{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search_space.operations import *\n",
    "from src.search_space.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Network(3, 12, 1, eval(\"Genotype(normal=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], normal_concat=[2, 3, 4, 5], reduce=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], reduce_concat=[2, 3, 4, 5])\"))\n",
    "# # print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from src.utils.utilities import *\n",
    "from src.metrics.swap import SWAP\n",
    "from src.datasets.utilities import get_datasets\n",
    "from src.search_space.networks import *\n",
    "\n",
    "# Settings for console outputs\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# general setting\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "SEED = 0\n",
    "REPEATS = 4\n",
    "INPUT_SAMPLE = 16\n",
    "\n",
    "\n",
    "\n",
    "input_file = open(\"input_2.txt\",\"r\")\n",
    "input_dim = 80\n",
    "inputs = []\n",
    "num = 0\n",
    "for input_data in input_file.readlines():\n",
    "    data = (input_data.split())[2:]\n",
    "    data_list = []\n",
    "    for i in range(input_dim):\n",
    "        data_list_list = []\n",
    "        for j in range(input_dim):\n",
    "            data_list_list.append(int(data[i*input_dim + j]))\n",
    "        data_list.append(data_list_list)\n",
    "\n",
    "    # the input chennel\n",
    "    inputs.append([data_list,data_list,data_list])\n",
    "    num += 1\n",
    "    if num >= 300:\n",
    "        break\n",
    "input_file.close()\n",
    "inputs = torch.Tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "# 定義基因型\n",
    "Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n",
    "PRIMITIVES = [\n",
    "    'none',\n",
    "    'max_pool_3x3',\n",
    "    'avg_pool_3x3',\n",
    "    'skip_connect',\n",
    "    'sep_conv_3x3',\n",
    "    'sep_conv_5x5',\n",
    "    'dil_conv_3x3',\n",
    "    'dil_conv_5x5'\n",
    "]\n",
    "\n",
    "def random_genotype():\n",
    "\n",
    "    steps=4\n",
    "    \n",
    "    def valid_random_ops(steps):\n",
    "        ops = []\n",
    "        for i in range(steps):\n",
    "            op1 = (random.choice(PRIMITIVES), random.randint(0, i + 1))\n",
    "            op2 = (random.choice(PRIMITIVES), random.randint(0, i + 1))\n",
    "            ops.append(op1)\n",
    "            ops.append(op2)\n",
    "        return ops\n",
    "\n",
    "    normal = valid_random_ops(steps)\n",
    "    reduce = valid_random_ops(steps)\n",
    "    normal_concat = list(range(2, 2 + steps))\n",
    "    reduce_concat = list(range(2, 2 + steps))\n",
    "    \n",
    "    genotype = Genotype(normal=normal, normal_concat=normal_concat, reduce=reduce, reduce_concat=reduce_concat)\n",
    "    \n",
    "    return genotype\n",
    "\n",
    "def evaluate_fitness(genotype):\n",
    "    network = Network(3, 12, 1, eval(str(genotype)))\n",
    "    network = network.to(device)\n",
    "    swap = SWAP(model=network, inputs=inputs, device=device, seed=SEED)\n",
    "    swap_score = []\n",
    "    for _ in range(REPEATS):\n",
    "        network = network.apply(network_weight_gaussian_init)\n",
    "        swap.reinit()\n",
    "        swap_score.append(swap.forward())\n",
    "        swap.clear()\n",
    "    return np.mean(swap_score)\n",
    "\n",
    "def mutate(genotype):\n",
    "    def mutate_ops(ops):\n",
    "        i = random.randint(0, 7)\n",
    "        if random.random() > 0.5:\n",
    "            ops[i] = (random.choice(PRIMITIVES), ops[i][1])\n",
    "        else:\n",
    "            if i < 2:\n",
    "                state = random.randint(0, 1)\n",
    "            elif i < 4:\n",
    "                state = random.randint(0, 2)\n",
    "            elif i < 6:\n",
    "                state = random.randint(0, 3)\n",
    "            else:\n",
    "                state = random.randint(0, 4)\n",
    "            ops[i] = (random.choice(PRIMITIVES), state)\n",
    "        return ops\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        return Genotype(\n",
    "            normal=mutate_ops(genotype.normal),\n",
    "            normal_concat=genotype.normal_concat,\n",
    "            reduce=genotype.reduce,\n",
    "            reduce_concat=genotype.reduce_concat\n",
    "        )\n",
    "    else:\n",
    "        return Genotype(\n",
    "            normal=genotype.normal,\n",
    "            normal_concat=genotype.normal_concat,\n",
    "            reduce=mutate_ops(genotype.reduce),\n",
    "            reduce_concat=genotype.reduce_concat\n",
    "        )\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    def mix_ops(ops1, ops2):\n",
    "        return [random.choice(pair) for pair in zip(ops1, ops2)]\n",
    "    \n",
    "    normal = mix_ops(parent1.normal, parent2.normal)\n",
    "    reduce = mix_ops(parent1.reduce, parent2.reduce)\n",
    "    \n",
    "    return Genotype(normal=normal, normal_concat=parent1.normal_concat, reduce=reduce, reduce_concat=parent1.reduce_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacity of 2.00 GiB of which 0 bytes is free. Of the allocated memory 866.13 MiB is allocated by PyTorch, and 63.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(population_size):\n\u001b[0;32m     13\u001b[0m     genotype \u001b[38;5;241m=\u001b[39m random_genotype()\n\u001b[1;32m---> 14\u001b[0m     population\u001b[38;5;241m.\u001b[39mappend((genotype, \u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenotype\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 遺傳演算法迴圈\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# 評估種群中的每個個體\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# fitnesses = [evaluate_fitness(genotype) for genotype in population]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 47\u001b[0m, in \u001b[0;36mevaluate_fitness\u001b[1;34m(genotype)\u001b[0m\n\u001b[0;32m     45\u001b[0m     network \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mapply(network_weight_gaussian_init)\n\u001b[0;32m     46\u001b[0m     swap\u001b[38;5;241m.\u001b[39mreinit()\n\u001b[1;32m---> 47\u001b[0m     swap_score\u001b[38;5;241m.\u001b[39mappend(\u001b[43mswap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     48\u001b[0m     swap\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(swap_score)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\EC_final\\SWAP-main\\src\\metrics\\swap.py:92\u001b[0m, in \u001b[0;36mSWAP.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterFeature) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     91\u001b[0m activtions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([f\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterFeature], \u001b[38;5;241m1\u001b[39m)         \n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivtions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswap\u001b[38;5;241m.\u001b[39mcalSWAP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregular_factor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\EC_final\\SWAP-main\\src\\metrics\\swap.py:28\u001b[0m, in \u001b[0;36mSampleWiseActivationPatterns.collect_activations\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n_sample, n_neuron)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacity of 2.00 GiB of which 0 bytes is free. Of the allocated memory 866.13 MiB is allocated by PyTorch, and 63.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 初始化種群\n",
    "population_size = 4\n",
    "# 遺傳演算法的參數\n",
    "num_generations = 5\n",
    "mutation_rate = 0.1\n",
    "tournament_size = 2\n",
    "\n",
    "best_fitness = -1\n",
    "best_genotype = None\n",
    "\n",
    "population = []\n",
    "for _ in range(population_size):\n",
    "    genotype = random_genotype()\n",
    "    population.append((genotype, evaluate_fitness(genotype)))\n",
    "\n",
    "\n",
    "\n",
    "# 遺傳演算法迴圈\n",
    "for generation in range(num_generations):\n",
    "    # 評估種群中的每個個體\n",
    "    # fitnesses = [evaluate_fitness(genotype) for genotype in population]\n",
    "    population = sorted(population, key=lambda x: -x[1])\n",
    "    for gene in population:\n",
    "        print(gene,end=\" \")\n",
    "    print(\"\")\n",
    "\n",
    "    max_fitness = population[0][1]\n",
    "    # max_index = fitnesses.index(max_fitness)\n",
    "    if max_fitness > best_fitness:\n",
    "        best_fitness = max_fitness\n",
    "        best_genotype = population[0][0]\n",
    "\n",
    "    # 打印當前世代的最佳適應度\n",
    "    print(f\"Generation {generation}: Best Fitness = {max_fitness} Genotype = {best_genotype}\")\n",
    "\n",
    "    # 選擇父代\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        tournament = random.sample(population, tournament_size)\n",
    "        tournament = sorted(tournament, key=lambda x: -x[1])\n",
    "        parent1 = tournament[0][0]\n",
    "        parent2 = tournament[1][0]\n",
    "        child = crossover(parent1, parent2)\n",
    "        if random.uniform(0, 1) < mutation_rate:\n",
    "            child = mutate(child)\n",
    "        new_population.append((child, evaluate_fitness(child)))\n",
    "    new_population = sorted(new_population, key=lambda x: -x[1])\n",
    "    \n",
    "    population[-1] = new_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
