{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.search_space.operations import *\n",
    "from src.search_space.networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Network(3, 12, 1, eval(\"Genotype(normal=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], normal_concat=[2, 3, 4, 5], reduce=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], reduce_concat=[2, 3, 4, 5])\"))\n",
    "# test = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from src.utils.utilities import *\n",
    "from src.metrics.swap import SWAP\n",
    "from src.datasets.utilities import get_datasets\n",
    "from src.search_space.networks import *\n",
    "\n",
    "# Settings for console outputs\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# general setting\n",
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "SEED = 0\n",
    "REPEATS = 4\n",
    "INPUT_SAMPLE = 16\n",
    "\n",
    "\n",
    "\n",
    "input_file = open(\"input_2.txt\",\"r\")\n",
    "input_dim = 80\n",
    "inputs = []\n",
    "num = 0\n",
    "for input_data in input_file.readlines():\n",
    "    data = (input_data.split())[2:]\n",
    "    data_list = []\n",
    "    for i in range(input_dim):\n",
    "        data_list_list = []\n",
    "        for j in range(input_dim):\n",
    "            data_list_list.append(int(data[i*input_dim + j]))\n",
    "        data_list.append(data_list_list)\n",
    "\n",
    "    # the input chennel\n",
    "    inputs.append([data_list,data_list,data_list])\n",
    "    num += 1\n",
    "    if num >= 300:\n",
    "        break\n",
    "input_file.close()\n",
    "inputs = torch.Tensor(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "# 定義基因型\n",
    "Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n",
    "PRIMITIVES = [\n",
    "    'none',\n",
    "    'max_pool_3x3',\n",
    "    'avg_pool_3x3',\n",
    "    'skip_connect',\n",
    "    'sep_conv_3x3',\n",
    "    'sep_conv_5x5',\n",
    "    'dil_conv_3x3',\n",
    "    'dil_conv_5x5'\n",
    "]\n",
    "\n",
    "def random_genotype():\n",
    "\n",
    "    steps=4\n",
    "    \n",
    "    def valid_random_ops(steps):\n",
    "        ops = []\n",
    "        for i in range(steps):\n",
    "            op1 = (random.choice(PRIMITIVES), random.randint(0, i + 1))\n",
    "            op2 = (random.choice(PRIMITIVES), random.randint(0, i + 1))\n",
    "            ops.append(op1)\n",
    "            ops.append(op2)\n",
    "        return ops\n",
    "\n",
    "    normal = valid_random_ops(steps)\n",
    "    reduce = valid_random_ops(steps)\n",
    "    normal_concat = list(range(2, 2 + steps))\n",
    "    reduce_concat = list(range(2, 2 + steps))\n",
    "    \n",
    "    genotype = Genotype(normal=normal, normal_concat=normal_concat, reduce=reduce, reduce_concat=reduce_concat)\n",
    "    \n",
    "    return genotype\n",
    "\n",
    "def evaluate_fitness(genotype):\n",
    "    network = Network(3, 12, 1, eval(str(genotype)))\n",
    "    network = network.to(device)\n",
    "    swap = SWAP(model=network, inputs=inputs, device=device, seed=SEED)\n",
    "    swap_score = []\n",
    "    for _ in range(REPEATS):\n",
    "        network = network.apply(network_weight_gaussian_init)\n",
    "        swap.reinit()\n",
    "        swap_score.append(swap.forward())\n",
    "        swap.clear()\n",
    "    return np.mean(swap_score)\n",
    "\n",
    "def mutate(genotype):\n",
    "    def mutate_ops(ops):\n",
    "        i = random.randint(0, 7)\n",
    "        if random.random() > 0.5:\n",
    "            ops[i] = (random.choice(PRIMITIVES), ops[i][1])\n",
    "        else:\n",
    "            if i < 2:\n",
    "                state = random.randint(0, 1)\n",
    "            elif i < 4:\n",
    "                state = random.randint(0, 2)\n",
    "            elif i < 6:\n",
    "                state = random.randint(0, 3)\n",
    "            else:\n",
    "                state = random.randint(0, 4)\n",
    "            ops[i] = (random.choice(PRIMITIVES), state)\n",
    "        return ops\n",
    "    \n",
    "    if random.random() > 0.5:\n",
    "        return Genotype(\n",
    "            normal=mutate_ops(genotype.normal),\n",
    "            normal_concat=genotype.normal_concat,\n",
    "            reduce=genotype.reduce,\n",
    "            reduce_concat=genotype.reduce_concat\n",
    "        )\n",
    "    else:\n",
    "        return Genotype(\n",
    "            normal=genotype.normal,\n",
    "            normal_concat=genotype.normal_concat,\n",
    "            reduce=mutate_ops(genotype.reduce),\n",
    "            reduce_concat=genotype.reduce_concat\n",
    "        )\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    def mix_ops(ops1, ops2):\n",
    "        return [random.choice(pair) for pair in zip(ops1, ops2)]\n",
    "    \n",
    "    normal = mix_ops(parent1.normal, parent2.normal)\n",
    "    reduce = mix_ops(parent1.reduce, parent2.reduce)\n",
    "    \n",
    "    return Genotype(normal=normal, normal_concat=parent1.normal_concat, reduce=reduce, reduce_concat=parent1.reduce_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacity of 2.00 GiB of which 0 bytes is free. Of the allocated memory 866.13 MiB is allocated by PyTorch, and 63.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(population_size):\n\u001b[0;32m     13\u001b[0m     genotype \u001b[38;5;241m=\u001b[39m random_genotype()\n\u001b[1;32m---> 14\u001b[0m     population\u001b[38;5;241m.\u001b[39mappend((genotype, \u001b[43mevaluate_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenotype\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 遺傳演算法迴圈\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_generations):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# 評估種群中的每個個體\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# fitnesses = [evaluate_fitness(genotype) for genotype in population]\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 47\u001b[0m, in \u001b[0;36mevaluate_fitness\u001b[1;34m(genotype)\u001b[0m\n\u001b[0;32m     45\u001b[0m     network \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mapply(network_weight_gaussian_init)\n\u001b[0;32m     46\u001b[0m     swap\u001b[38;5;241m.\u001b[39mreinit()\n\u001b[1;32m---> 47\u001b[0m     swap_score\u001b[38;5;241m.\u001b[39mappend(\u001b[43mswap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     48\u001b[0m     swap\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(swap_score)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\EC_final\\SWAP-main\\src\\metrics\\swap.py:92\u001b[0m, in \u001b[0;36mSWAP.forward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterFeature) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     91\u001b[0m activtions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([f\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterFeature], \u001b[38;5;241m1\u001b[39m)         \n\u001b[1;32m---> 92\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_activations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivtions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswap\u001b[38;5;241m.\u001b[39mcalSWAP(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregular_factor)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\EC_final\\SWAP-main\\src\\metrics\\swap.py:28\u001b[0m, in \u001b[0;36mSampleWiseActivationPatterns.collect_activations\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(n_sample, n_neuron)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 286.00 MiB. GPU 0 has a total capacity of 2.00 GiB of which 0 bytes is free. Of the allocated memory 866.13 MiB is allocated by PyTorch, and 63.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 初始化種群\n",
    "population_size = 4\n",
    "# 遺傳演算法的參數\n",
    "num_generations = 5\n",
    "mutation_rate = 0.1\n",
    "tournament_size = 2\n",
    "\n",
    "best_fitness = -1\n",
    "best_genotype = None\n",
    "\n",
    "population = []\n",
    "for _ in range(population_size):\n",
    "    genotype = random_genotype()\n",
    "    population.append((genotype, evaluate_fitness(genotype)))\n",
    "\n",
    "\n",
    "\n",
    "# 遺傳演算法迴圈\n",
    "for generation in range(num_generations):\n",
    "    # 評估種群中的每個個體\n",
    "    # fitnesses = [evaluate_fitness(genotype) for genotype in population]\n",
    "    population = sorted(population, key=lambda x: -x[1])\n",
    "    for gene in population:\n",
    "        print(gene,end=\" \")\n",
    "    print(\"\")\n",
    "\n",
    "    max_fitness = population[0][1]\n",
    "    # max_index = fitnesses.index(max_fitness)\n",
    "    if max_fitness > best_fitness:\n",
    "        best_fitness = max_fitness\n",
    "        best_genotype = population[0][0]\n",
    "\n",
    "    # 打印當前世代的最佳適應度\n",
    "    print(f\"Generation {generation}: Best Fitness = {max_fitness} Genotype = {best_genotype}\")\n",
    "\n",
    "    # 選擇父代\n",
    "    new_population = []\n",
    "    for _ in range(population_size):\n",
    "        tournament = random.sample(population, tournament_size)\n",
    "        tournament = sorted(tournament, key=lambda x: -x[1])\n",
    "        parent1 = tournament[0][0]\n",
    "        parent2 = tournament[1][0]\n",
    "        child = crossover(parent1, parent2)\n",
    "        if random.uniform(0, 1) < mutation_rate:\n",
    "            child = mutate(child)\n",
    "        new_population.append((child, evaluate_fitness(child)))\n",
    "    new_population = sorted(new_population, key=lambda x: -x[1])\n",
    "    \n",
    "    population[-1] = new_population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "OPS = {\n",
    "    'none': lambda C_in, C_out, stride, affine: Zero(C_in, C_out, stride),\n",
    "    'avg_pool_3x3': lambda C_in, C_out, stride, affine: POOLING(C_in, C_out, stride, 'avg', affine),\n",
    "    'max_pool_3x3': lambda C_in, C_out, stride, affine: POOLING(C_in, C_out, stride, 'max', affine),\n",
    "    'skip_connect': lambda C_in, C_out, stride, affine: Identity() if stride == 1 and C_in == C_out else FactorizedReduce(C_in, C_out, stride, affine),\n",
    "    'sep_conv_3x3': lambda C_in, C_out, stride, affine: SepConv(C_in, C_out, 3, stride, 1, affine),\n",
    "    'sep_conv_5x5': lambda C_in, C_out, stride, affine: SepConv(C_in, C_out, 5, stride, 2, affine),\n",
    "    'dil_conv_3x3': lambda C_in, C_out, stride, affine: DilConv(C_in, C_out, 3, stride, 2, 2, affine),\n",
    "    'dil_conv_5x5': lambda C_in, C_out, stride, affine: DilConv(C_in, C_out, 5, stride, 4, 2, affine),\n",
    "}\n",
    "\n",
    "\n",
    "class ReLUConvBN(nn.Module):\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine, track_running_stats=True):\n",
    "        super(ReLUConvBN, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(C_in, C_out, kernel_size, stride=stride, padding=padding, dilation=dilation, bias=False),\n",
    "            nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class DilConv(nn.Module):\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, dilation, affine=True, track_running_stats=True):\n",
    "        super(DilConv, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation,\n",
    "                      groups=C_in, bias=False),\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class SepConv(nn.Module):\n",
    "\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, padding, affine=True, track_running_stats=True):\n",
    "        super(SepConv, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=stride, padding=padding, groups=C_in, bias=False),\n",
    "            nn.Conv2d(C_in, C_in, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(C_in, affine=affine, track_running_stats=track_running_stats),\n",
    "            \n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(C_in, C_in, kernel_size=kernel_size, stride=1, padding=padding, groups=C_in, bias=False),\n",
    "            nn.Conv2d(C_in, C_out, kernel_size=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class Identity(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class FactorizedReduce(nn.Module):\n",
    "    def __init__(self, C_in, C_out, stride=2, affine=True, track_running_stats=True):\n",
    "        super(FactorizedReduce, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.C_in   = C_in\n",
    "        self.C_out  = C_out\n",
    "        self.relu   = nn.ReLU(inplace=False)\n",
    "        if stride == 2:\n",
    "            C_outs = [C_out // 2, C_out - C_out // 2]\n",
    "            self.convs = nn.ModuleList()\n",
    "            for i in range(2):\n",
    "                self.convs.append( nn.Conv2d(C_in, C_outs[i], 1, stride=stride, padding=0, bias=False))\n",
    "            self.pad = nn.ConstantPad2d((0, 1, 0, 1), 0)\n",
    "        elif stride == 1:\n",
    "            self.conv = nn.Conv2d(C_in, C_out, 1, stride=stride, padding=0, bias=False)\n",
    "        else:\n",
    "            raise ValueError('Invalid stride : {:}'.format(stride))\n",
    "        self.bn = nn.BatchNorm2d(C_out, affine=affine, track_running_stats=track_running_stats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stride == 2:\n",
    "            x = self.relu(x)\n",
    "            y = self.pad(x)\n",
    "            out = torch.cat([self.convs[0](x), self.convs[1](y[:, :, 1:, 1:])], dim=1)\n",
    "        else:\n",
    "            out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        return out\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'C_in={C_in}, C_out={C_out}, stride={stride}'.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class Zero(nn.Module):\n",
    "\n",
    "    def __init__(self, C_in, C_out, stride):\n",
    "        super(Zero, self).__init__()\n",
    "        self.C_in   = C_in\n",
    "        self.C_out  = C_out\n",
    "        self.stride = stride\n",
    "        self.is_zero = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.C_in == self.C_out:\n",
    "            if self.stride == 1: return x.mul(0.)\n",
    "            else               : return x[:,:,::self.stride,::self.stride].mul(0.)\n",
    "        else:\n",
    "            shape = list(x.shape)\n",
    "            shape[1] = self.C_out\n",
    "            zeros = x.new_zeros(shape, dtype=x.dtype, device=x.device)\n",
    "            return zeros\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'C_in={C_in}, C_out={C_out}, stride={stride}'.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class POOLING(nn.Module):\n",
    "\n",
    "    def __init__(self, C_in, C_out, stride, mode, affine=True, track_running_stats=True):\n",
    "        super(POOLING, self).__init__()\n",
    "        if C_in == C_out:\n",
    "            self.preprocess = None\n",
    "        else:\n",
    "            self.preprocess = ReLUConvBN(C_in, C_out, 1, 1, 0, 1, affine, track_running_stats)\n",
    "        if mode == 'avg'  : self.op = nn.AvgPool2d(3, stride=stride, padding=1, count_include_pad=False)\n",
    "        elif mode == 'max': self.op = nn.MaxPool2d(3, stride=stride, padding=1)\n",
    "        else              : raise ValueError('Invalid mode={:} in POOLING'.format(mode))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.preprocess: x = self.preprocess(inputs)\n",
    "        else              : x = inputs\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple\n",
    "\n",
    "Genotype = namedtuple('Genotype', 'normal normal_concat reduce reduce_concat')\n",
    "\n",
    "def drop_path(x, drop_prob):\n",
    "  if drop_prob > 0.:\n",
    "    x = nn.functional.dropout(x, p=drop_prob)\n",
    "\n",
    "  return x\n",
    "\n",
    "class Cell(nn.Module):\n",
    "\n",
    "  def __init__(self, genotype, C_prev_prev, C_prev, C, reduction, reduction_prev):\n",
    "    super(Cell, self).__init__()\n",
    "\n",
    "    if reduction_prev:\n",
    "      self.preprocess0 = FactorizedReduce(C_prev_prev, C)\n",
    "    else:\n",
    "      self.preprocess0 = ReLUConvBN(C_prev_prev, C, 1, 1, 0, 1, True)\n",
    "    self.preprocess1 = ReLUConvBN(C_prev, C, 1, 1, 0, 1, True)\n",
    "    \n",
    "    if reduction:\n",
    "        op_names, indices = zip(*genotype.reduce)\n",
    "        concat = genotype.reduce_concat # 2,3,4,5\n",
    "    else:\n",
    "        op_names, indices = zip(*genotype.normal)\n",
    "        concat = genotype.normal_concat # 2,3,4,5\n",
    "    self._compile(C, op_names, indices, concat, reduction)\n",
    "\n",
    "  def _compile(self, C, op_names, indices, concat, reduction):\n",
    "    assert len(op_names) == len(indices)\n",
    "    self._steps = len(op_names) // 2 # 4\n",
    "    self._concat = concat # 2,3,4,5\n",
    "    self.multiplier = len(concat) # 4\n",
    "    self._ops = nn.ModuleList()\n",
    "\n",
    "    for name, index in zip(op_names, indices):\n",
    "        stride = 2 if reduction and index < 2 else 1\n",
    "        op = OPS[name](C, C, stride, True)\n",
    "        self._ops += [op]\n",
    "    self._indices = indices\n",
    "\n",
    "  def forward(self, s0, s1, drop_prob):\n",
    "    s0 = self.preprocess0(s0)\n",
    "    s1 = self.preprocess1(s1)\n",
    "\n",
    "    states = [s0, s1]\n",
    "    for i in range(self._steps):\n",
    "      # print(f\"i: {i}\")\n",
    "      h1 = states[self._indices[2*i]]\n",
    "      h2 = states[self._indices[2*i+1]]\n",
    "      op1 = self._ops[2*i]\n",
    "      op2 = self._ops[2*i+1]\n",
    "      h1 = op1(h1)\n",
    "      h2 = op2(h2)\n",
    "      if self.training and drop_prob > 0.:\n",
    "        if not isinstance(op1, Identity):\n",
    "          h1 = drop_path(h1, drop_prob)\n",
    "        if not isinstance(op2, Identity):\n",
    "          h2 = drop_path(h2, drop_prob)\n",
    "      s = h1 + h2\n",
    "      states += [s]\n",
    "    return torch.cat([states[i] for i in self._concat], dim=1)\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, C, num_classes, layers, genotype):\n",
    "        self.drop_path_prob = 0.\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self._layers = layers\n",
    "\n",
    "        C_prev_prev, C_prev, C_curr = C, C, C\n",
    "        \n",
    "        self.cells = nn.ModuleList()\n",
    "        reduction_prev = False\n",
    "\n",
    "        for i in range(layers):\n",
    "            if i in [layers // 3, 2 * layers // 3]:\n",
    "                C_curr *= 2\n",
    "                reduction = True\n",
    "            else:\n",
    "                reduction = False\n",
    "            cell = Cell(genotype, C_prev_prev, C_prev, C_curr, reduction, reduction_prev)\n",
    "            reduction_prev = reduction\n",
    "            self.cells += [cell]\n",
    "            C_prev_prev, C_prev = C_prev, cell.multiplier * C_curr\n",
    "\n",
    "        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(C_prev, num_classes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        s0 = s1 = input\n",
    "        \n",
    "        for i, cell in enumerate(self.cells):\n",
    "            s0, s1 = s1, cell(s0, s1, self.drop_path_prob)\n",
    "\n",
    "        out = self.global_pooling(s1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        logits = self.classifier(out)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 512, 3)\n",
      "(32, 32, 3)\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n",
      "torch.Size([1, 3, 32, 32])\n",
      "============== score ====================\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import wrapped_flappy_bird as game\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ACTIONS = 2 \n",
    "\n",
    "game_state = game.GameState()\n",
    "\n",
    "\n",
    "#初始化状态并且预处理图片，把连续的四帧图像作为一个输入（State）\n",
    "do_nothing = np.zeros(ACTIONS)\n",
    "do_nothing[0] = 1\n",
    "s_t, r_0, terminal, _ = game_state.frame_step(do_nothing)\n",
    "s_t = cv2.cvtColor(cv2.resize(s_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "model = Network(3, 2, 1, eval(str(\"Genotype(normal=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], normal_concat=[2, 3, 4, 5], reduce=[('none', 0), ('dil_conv_5x5', 0), ('sep_conv_5x5', 0), ('sep_conv_3x3', 1), ('sep_conv_3x3', 1), ('dil_conv_5x5', 2), ('sep_conv_5x5', 3), ('skip_connect', 4)], reduce_concat=[2, 3, 4, 5])\")))\n",
    "\n",
    "while terminal !=True:\n",
    "    a_t_to_game = np.zeros([ACTIONS])\n",
    "    action_index = 0\n",
    "    s_t = cv2.cvtColor(cv2.resize(s_t, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    s_t = torch.tensor(s_t, dtype=torch.float32)\n",
    "    s_t = s_t.permute(2, 0, 1)\n",
    "    s_t = s_t.unsqueeze(0)\n",
    "\n",
    "    print(s_t.shape)\n",
    "\n",
    "    readout_t = model(s_t)\n",
    "    action_index = np.argmax(readout_t.detach().cpu().numpy())\n",
    "    a_t_to_game[action_index] = 1\n",
    "\n",
    "    s_t, r_t, terminal, score = game_state.frame_step(a_t_to_game)\n",
    "    print(\"============== score ====================\")\n",
    "    print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
