{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from src.utils.utilities import *\n",
    "from src.metrics.swap import SWAP\n",
    "from src.datasets.utilities import get_datasets\n",
    "from src.search_space.networks import *\n",
    "\n",
    "# Settings for console outputs\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets\"\n",
    "seed = 0\n",
    "device = \"cpu\"\n",
    "repeats = 32\n",
    "input_samples = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path [DATA_PATH]] [--seed SEED]\n",
      "                             [--device [DEVICE]] [--repeats [REPEATS]]\n",
      "                             [--input_samples [INPUT_SAMPLES]]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\USER\\AppData\\Roaming\\jupyter\\runtime\\kernel-v2-22744y6rbtiVsW0Mb.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "\n",
    "# # general setting\n",
    "# parser.add_argument('--data_path', default=\"datasets\", type=str, nargs='?', help='path to the image dataset (datasets or datasets/ILSVRC/Data/CLS-LOC)')\n",
    "# parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "# parser.add_argument('--device', default=\"cpu\", type=str, nargs='?', help='setup device (cpu, mps or cuda)')\n",
    "# parser.add_argument('--repeats', default=32, type=int, nargs='?', help='times of calculating the training-free metric')\n",
    "# parser.add_argument('--input_samples', default=16, type=int, nargs='?', help='input batch size for training-free metric')\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(device)\n",
    "\n",
    "arch_info = pd.read_csv(data_path+'/DARTS_archs_CIFAR10.csv', names=['genotype', 'valid_acc'], sep=',')\n",
    "\n",
    "train_data, _, _ = get_datasets('cifar10', data_path, (input_samples, 3, 32, 32), -1)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=input_samples, num_workers=0, pin_memory=True)\n",
    "loader = iter(train_loader)\n",
    "inputs, _ = next(loader)  \n",
    "\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              genotype  valid_acc\n",
      "0    Genotype(normal=[('none', 0), ('dil_conv_5x5',...  85.000000\n",
      "1    Genotype(normal=[('sep_conv_5x5', 0), ('sep_co...  85.239998\n",
      "2    Genotype(normal=[('dil_conv_5x5', 0), ('skip_c...  81.290001\n",
      "3    Genotype(normal=[('dil_conv_5x5', 0), ('sep_co...  77.720001\n",
      "4    Genotype(normal=[('none', 1), ('sep_conv_3x3',...  82.040001\n",
      "..                                                 ...        ...\n",
      "995  Genotype(normal=[('dil_conv_3x3', 0), ('dil_co...  74.369995\n",
      "996  Genotype(normal=[('dil_conv_5x5', 1), ('max_po...  80.290001\n",
      "997  Genotype(normal=[('sep_conv_3x3', 1), ('avg_po...  79.059998\n",
      "998  Genotype(normal=[('sep_conv_3x3', 1), ('dil_co...  79.889999\n",
      "999  Genotype(normal=[('avg_pool_3x3', 1), ('dil_co...  79.199997\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(arch_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in arch_info.iterrows():\n",
    "    print(f'Evaluating network: {index}')\n",
    "\n",
    "    network = Network(3, 10, 1, eval(i.genotype))\n",
    "    network = network.to(device)\n",
    "\n",
    "    swap = SWAP(model=network, inputs=inputs, device=device, seed=seed)\n",
    "\n",
    "    swap_score = []\n",
    "\n",
    "    for _ in range(repeats):\n",
    "        network = network.apply(network_weight_gaussian_init)\n",
    "        swap.reinit()\n",
    "        swap_score.append(swap.forward())\n",
    "        swap.clear()\n",
    "\n",
    "    results.append([np.mean(swap_score), i.valid_acc])\n",
    "\n",
    "results = pd.DataFrame(results, columns=['swap_score', 'valid_acc'])\n",
    "print()    \n",
    "print(f'Spearman\\'s Correlation Coefficient: {stats.spearmanr(results.swap_score, results.valid_acc)[0]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
